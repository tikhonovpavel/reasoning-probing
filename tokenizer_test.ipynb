{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32853a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- QwQ prompt: --\n",
      "<|im_start|>user\n",
      "What is 1 + 2?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The answer is 3.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "tokenizer_qwq = AutoTokenizer.from_pretrained(\"Qwen/QwQ-32B\")\n",
    "prompt_qwq = tokenizer_qwq.apply_chat_template(\n",
    "\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": \"What is 1 + 2?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The answer is 3.\"}\n",
    "    ],\n",
    "    tokenize=False\n",
    ")\n",
    "\n",
    "print('-- QwQ prompt: --')\n",
    "print(prompt_qwq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebda24ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Qwen3 full prompt: --\n",
      "<|im_start|>user\n",
      "What is 1 + 2?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The answer is 3.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_qwen3 = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-32B\")\n",
    "prompt_qwen3 = tokenizer_qwen3.apply_chat_template(\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": \"What is 1 + 2?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The answer is 3.\"}\n",
    "    ],\n",
    "    tokenize=False\n",
    ")\n",
    "\n",
    "print('-- Qwen3 full prompt: --')\n",
    "print(prompt_qwen3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58683a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Qwen3 only user prompt: --\n",
      "<|im_start|>user\n",
      "What is 1 + 2?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_qwen3_only_user = tokenizer_qwen3.apply_chat_template(\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": \"What is 1 + 2?\"},\n",
    "    ],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print('-- Qwen3 only user prompt: --')\n",
    "print(prompt_qwen3_only_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a29b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Qwen3 output: --\n",
      "<|im_start|>user\n",
      "What is 1 + 2?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "Okay, so the question is asking, what is 1 plus 2? Let me think. Well, I know that in mathematics, addition is the operation that combines two numbers. So, 1 plus 2 would be combining the two numbers. Let me visualize this. If I have a number line, starting at 1, and then adding 2, that would take me to 3. So, 1 plus 2 equals 3. \n",
      "\n",
      "Wait, but maybe I should check if there's any trick here. Sometimes problems can be tricky, like if they're in a different context or if there's a special rule. But in basic arithmetic, addition is straightforward. So, 1 plus 2 is definitely 3. \n",
      "\n",
      "I don't think there's anything else to it. Maybe if there's a different interpretation, like if they're asking about something else, but the question is very simple. 1 plus 2 is a basic addition problem. So, the answer should be 3. \n",
      "\n",
      "I should also consider if there's any possible misunderstanding, like if they're asking for something else, but no, the question is directly asking for 1 plus 2. So, I think the answer is 3.\n",
      "</think>\n",
      "\n",
      "1 + 2 equals 3. \n",
      "\n",
      "The operation of addition combines the two numbers, so 1 + 2 is calculated by adding 1 and 2 together. The result is 3. \n",
      "\n",
      "**Answer:** 3<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "model_qwen3 = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B\", device_map=\"cuda\")\n",
    "output = model_qwen3.generate(tokenizer_qwen3.encode(prompt_qwen3_only_user, return_tensors=\"pt\").to(\"cuda\"), max_new_tokens=512)\n",
    "print('-- Qwen3 output: --')\n",
    "print(tokenizer_qwen3.decode(output[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf2196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39914cbf",
   "metadata": {},
   "source": [
    "So the conclusions are: \n",
    "1) QwQ does NOT have <think></think> tags structure for reasoning, but Qwen3 have.\n",
    "2) When given the assistant's response, Qwen3's apply_chat_template does add <think></think> tags automatically, however with empty content.\n",
    "3) When given only the user's prompt, Qwen3's apply_chat_template does NOT add <think> tag. Instead the model knows to start with the opening tag <think> itself. And after the reasoning chain, it closes the tag and then continues with the direct response to the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0dccb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d393879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Wait'), (2, ','), (3, 'Ġbut'), (4, 'Ġmaybe'), (5, 'ĠI'), (6, 'Ġm'), (7, 'iscal'), (8, 'culated'), (9, '.'), (10, 'ĠLet'), (11, 'Ġme'), (12, 'Ġverify'), (13, 'Ġeach'), (14, 'Ġstep'), (15, 'Ġagain'), (16, '.')]\n"
     ]
    }
   ],
   "source": [
    "string = \"Wait, but maybe I miscalculated. Let me verify each step again.\"\n",
    "# print(AutoTokenizer.from_pretrained('Qwen/Qwen3-32B').tokenize(string))\n",
    "print(list(enumerate(AutoTokenizer.from_pretrained('Qwen/Qwen3-0.6B').tokenize(string), start=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae_reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
